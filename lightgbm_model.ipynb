{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "809ffec6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====================================================\n",
    "# STEP 1: Import Libraries\n",
    "# ====================================================\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.metrics import (\n",
    "    roc_auc_score, classification_report, confusion_matrix, \n",
    "    roc_curve, precision_recall_curve, average_precision_score,\n",
    "    accuracy_score, precision_score, recall_score, f1_score\n",
    ")\n",
    "import lightgbm as lgb\n",
    "from lightgbm import LGBMClassifier\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"LightGBM Version:\", lgb.__version__)\n",
    "print(\"âœ… Libraries imported successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "026acce7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====================================================\n",
    "# STEP 2: Load Data\n",
    "# ====================================================\n",
    "\n",
    "train_transaction = pd.read_csv(f\"./train_transaction.csv\")\n",
    "test_transaction  = pd.read_csv(f\"./test_transaction.csv\")\n",
    "\n",
    "print(f\"Train shape: {train_transaction.shape}\")\n",
    "print(f\"Test shape: {test_transaction.shape}\")\n",
    "print(f\"\\nTrain dataset info:\")\n",
    "print(f\"Columns: {train_transaction.shape[1]}\")\n",
    "print(f\"Rows: {train_transaction.shape[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35254344",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====================================================\n",
    "# STEP 3: Data Preprocessing\n",
    "# ====================================================\n",
    "\n",
    "# Separate features and target\n",
    "X = train_transaction.drop(['isFraud', 'TransactionID'], axis=1)\n",
    "y = train_transaction['isFraud']\n",
    "X_test_final = test_transaction.drop(['TransactionID'], axis=1)\n",
    "test_ids = test_transaction['TransactionID']\n",
    "\n",
    "print(f\"Features shape: {X.shape}\")\n",
    "print(f\"Target shape: {y.shape}\")\n",
    "print(f\"Test features shape: {X_test_final.shape}\")\n",
    "\n",
    "# Identify column types\n",
    "numerical_cols = X.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
    "categorical_cols = X.select_dtypes(include=['object']).columns.tolist()\n",
    "\n",
    "print(f\"\\nNumerical columns: {len(numerical_cols)}\")\n",
    "print(f\"Categorical columns: {len(categorical_cols)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52e6f719",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====================================================\n",
    "# STEP 4: Handle Missing Values\n",
    "# ====================================================\n",
    "\n",
    "# Check missing values percentage\n",
    "missing_pct = (X.isnull().sum() / len(X) * 100).sort_values(ascending=False)\n",
    "print(\"Top 20 columns with highest missing values (%)\")\n",
    "print(missing_pct.head(20))\n",
    "\n",
    "# Drop columns with >90% missing values\n",
    "high_missing_cols = missing_pct[missing_pct > 90].index.tolist()\n",
    "print(f\"\\nDropping {len(high_missing_cols)} columns with >90% missing values\")\n",
    "\n",
    "X = X.drop(columns=high_missing_cols)\n",
    "X_test_final = X_test_final.drop(columns=high_missing_cols)\n",
    "\n",
    "print(f\"New features shape: {X.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4d1d00d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====================================================\n",
    "# STEP 5: Label Encoding for Categorical Columns\n",
    "# ====================================================\n",
    "\n",
    "# Update categorical columns list after dropping\n",
    "categorical_cols = X.select_dtypes(include=['object']).columns.tolist()\n",
    "print(f\"Categorical columns to encode: {categorical_cols}\")\n",
    "\n",
    "# Label Encoding\n",
    "label_encoders = {}\n",
    "for col in categorical_cols:\n",
    "    le = LabelEncoder()\n",
    "    # Combine train and test for consistent encoding\n",
    "    combined = pd.concat([X[col].astype(str), X_test_final[col].astype(str)])\n",
    "    le.fit(combined)\n",
    "    \n",
    "    X[col] = le.transform(X[col].astype(str))\n",
    "    X_test_final[col] = le.transform(X_test_final[col].astype(str))\n",
    "    label_encoders[col] = le\n",
    "\n",
    "print(f\"\\nâœ… Encoded {len(categorical_cols)} categorical columns\")\n",
    "print(f\"Final X shape: {X.shape}\")\n",
    "print(f\"Final X_test shape: {X_test_final.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c16ee58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====================================================\n",
    "# STEP 6: Fill Remaining Missing Values\n",
    "# ====================================================\n",
    "\n",
    "# Fill numerical missing values with median\n",
    "numerical_cols = X.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
    "for col in numerical_cols:\n",
    "    if X[col].isnull().sum() > 0:\n",
    "        median_val = X[col].median()\n",
    "        X[col] = X[col].fillna(median_val)\n",
    "        X_test_final[col] = X_test_final[col].fillna(median_val)\n",
    "\n",
    "print(f\"Missing values in X after filling: {X.isnull().sum().sum()}\")\n",
    "print(f\"Missing values in X_test after filling: {X_test_final.isnull().sum().sum()}\")\n",
    "print(\"âœ… Data preprocessing completed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b5ebf26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====================================================\n",
    "# STEP 7: Train-Validation Split\n",
    "# ====================================================\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X, y,\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    "    stratify=y  # Stratified split to maintain class distribution\n",
    ")\n",
    "\n",
    "print(\"Train-Validation Split:\")\n",
    "print(f\"X_train: {X_train.shape}\")\n",
    "print(f\"X_val: {X_val.shape}\")\n",
    "print(f\"y_train distribution:\\n{y_train.value_counts(normalize=True)}\")\n",
    "print(f\"\\ny_val distribution:\\n{y_val.value_counts(normalize=True)}\")\n",
    "\n",
    "# Calculate class weights\n",
    "scale_pos_weight = (y_train == 0).sum() / (y_train == 1).sum()\n",
    "print(f\"\\nClass imbalance ratio: 1:{scale_pos_weight:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea8ccd10",
   "metadata": {},
   "source": [
    "## LightGBM Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffb19a09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====================================================\n",
    "# STEP 8: Baseline LightGBM Model\n",
    "# ====================================================\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"TRAINING BASELINE LightGBM MODEL\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Baseline parameters\n",
    "baseline_params = {\n",
    "    'num_leaves': 31,\n",
    "    'max_depth': 8,\n",
    "    'learning_rate': 0.1,\n",
    "    'n_estimators': 100,\n",
    "    'subsample': 0.8,\n",
    "    'colsample_bytree': 0.8,\n",
    "    'scale_pos_weight': scale_pos_weight,\n",
    "    'is_unbalance': True,\n",
    "    'objective': 'binary',\n",
    "    'metric': 'auc',\n",
    "    'random_state': 42,\n",
    "    'n_jobs': -1,\n",
    "    'verbose': -1\n",
    "}\n",
    "\n",
    "print(\"Baseline Parameters:\")\n",
    "for key, value in baseline_params.items():\n",
    "    print(f\"  {key}: {value}\")\n",
    "\n",
    "# Train baseline model\n",
    "baseline_lgb = LGBMClassifier(**baseline_params)\n",
    "baseline_lgb.fit(\n",
    "    X_train, y_train,\n",
    "    eval_set=[(X_train, y_train), (X_val, y_val)],\n",
    "    callbacks=[\n",
    "        lgb.log_evaluation(period=20),\n",
    "        lgb.early_stopping(stopping_rounds=50)\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Baseline predictions\n",
    "y_val_pred_proba_baseline = baseline_lgb.predict_proba(X_val)[:, 1]\n",
    "baseline_auc = roc_auc_score(y_val, y_val_pred_proba_baseline)\n",
    "baseline_ap = average_precision_score(y_val, y_val_pred_proba_baseline)\n",
    "\n",
    "print(f\"\\nðŸŽ¯ Baseline Validation ROC-AUC: {baseline_auc:.4f}\")\n",
    "print(f\"ðŸŽ¯ Baseline Validation PR-AUC: {baseline_ap:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fe173bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====================================================\n",
    "# STEP 9: Hyperparameter Tuning with Optuna\n",
    "# ====================================================\n",
    "\n",
    "try:\n",
    "    import optuna\n",
    "    print(\"Optuna version:\", optuna.__version__)\n",
    "    \n",
    "    def objective(trial):\n",
    "        params = {\n",
    "            'num_leaves': trial.suggest_int('num_leaves', 20, 100),\n",
    "            'max_depth': trial.suggest_int('max_depth', 5, 15),\n",
    "            'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.3, log=True),\n",
    "            'subsample': trial.suggest_float('subsample', 0.7, 1.0),\n",
    "            'colsample_bytree': trial.suggest_float('colsample_bytree', 0.7, 1.0),\n",
    "            'min_child_samples': trial.suggest_int('min_child_samples', 5, 30),\n",
    "            'scale_pos_weight': scale_pos_weight,\n",
    "            'is_unbalance': True,\n",
    "            'objective': 'binary',\n",
    "            'metric': 'auc',\n",
    "            'random_state': 42,\n",
    "            'n_jobs': -1,\n",
    "            'verbose': -1\n",
    "        }\n",
    "        \n",
    "        lgb_model = LGBMClassifier(n_estimators=200, **params)\n",
    "        \n",
    "        # Use stratified K-fold cross-validation\n",
    "        skf = StratifiedKFold(n_splits=3, shuffle=True, random_state=42)\n",
    "        scores = []\n",
    "        \n",
    "        for train_idx, val_idx in skf.split(X_train, y_train):\n",
    "            X_tr, X_v = X_train.iloc[train_idx], X_train.iloc[val_idx]\n",
    "            y_tr, y_v = y_train.iloc[train_idx], y_train.iloc[val_idx]\n",
    "            \n",
    "            lgb_model.fit(X_tr, y_tr, eval_set=[(X_v, y_v)], callbacks=[lgb.early_stopping(50), lgb.log_evaluation(0)])\n",
    "            y_pred = lgb_model.predict_proba(X_v)[:, 1]\n",
    "            auc = roc_auc_score(y_v, y_pred)\n",
    "            scores.append(auc)\n",
    "        \n",
    "        return np.mean(scores)\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"HYPERPARAMETER TUNING WITH OPTUNA\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    # Create study\n",
    "    sampler = optuna.samplers.TPESampler(seed=42)\n",
    "    study = optuna.create_study(direction='maximize', sampler=sampler)\n",
    "    \n",
    "    # Optimize (limited trials for faster execution)\n",
    "    study.optimize(objective, n_trials=20, show_progress_bar=True)\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"BEST PARAMETERS FOUND:\")\n",
    "    print(\"=\"*60)\n",
    "    best_params = study.best_params.copy()\n",
    "    for param, value in best_params.items():\n",
    "        print(f\"  {param}: {value}\")\n",
    "    print(f\"\\nBest CV AUC: {study.best_value:.4f}\")\n",
    "\n",
    "except ImportError:\n",
    "    print(\"âš ï¸ Optuna not installed. Skipping hyperparameter tuning.\")\n",
    "    print(\"Install with: pip install optuna\")\n",
    "    best_params = baseline_params.copy()\n",
    "    best_params.pop('n_estimators')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7190e03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====================================================\n",
    "# STEP 10: Train Final LightGBM Model\n",
    "# ====================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"TRAINING FINAL LightGBM MODEL\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Final model parameters\n",
    "final_params = best_params.copy() if 'best_params' in locals() else baseline_params.copy()\n",
    "final_params.update({\n",
    "    'n_estimators': 500,\n",
    "    'objective': 'binary',\n",
    "    'metric': 'auc',\n",
    "    'random_state': 42,\n",
    "    'n_jobs': -1,\n",
    "    'verbose': -1\n",
    "})\n",
    "\n",
    "# Train final model\n",
    "final_lgb = LGBMClassifier(**final_params)\n",
    "final_lgb.fit(\n",
    "    X_train, y_train,\n",
    "    eval_set=[(X_train, y_train), (X_val, y_val)],\n",
    "    callbacks=[\n",
    "        lgb.log_evaluation(period=50),\n",
    "        lgb.early_stopping(stopping_rounds=50)\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Final predictions\n",
    "y_val_pred_proba_final = final_lgb.predict_proba(X_val)[:, 1]\n",
    "y_val_pred_final = (y_val_pred_proba_final > 0.5).astype(int)\n",
    "\n",
    "final_auc = roc_auc_score(y_val, y_val_pred_proba_final)\n",
    "final_ap = average_precision_score(y_val, y_val_pred_proba_final)\n",
    "\n",
    "print(f\"\\nðŸŽ¯ Final Model Validation ROC-AUC: {final_auc:.4f}\")\n",
    "print(f\"ðŸŽ¯ Final Model Validation PR-AUC: {final_ap:.4f}\")\n",
    "print(f\"ðŸ“ˆ Improvement over baseline: {(final_auc - baseline_auc) * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4039ab24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====================================================\n",
    "# STEP 11: Model Evaluation\n",
    "# ====================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"MODEL EVALUATION METRICS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Classification Report\n",
    "print(\"\\nðŸ“Š CLASSIFICATION REPORT:\")\n",
    "print(\"-\" * 40)\n",
    "print(classification_report(y_val, y_val_pred_final, target_names=['Non-Fraud', 'Fraud']))\n",
    "\n",
    "# Confusion Matrix\n",
    "cm = confusion_matrix(y_val, y_val_pred_final)\n",
    "print(\"\\nðŸ”¢ CONFUSION MATRIX:\")\n",
    "print(cm)\n",
    "\n",
    "# Additional Metrics\n",
    "tn, fp, fn, tp = cm.ravel()\n",
    "print(f\"\\nðŸ“ˆ ADDITIONAL METRICS:\")\n",
    "print(f\"  True Negatives: {tn:,}\")\n",
    "print(f\"  False Positives: {fp:,}\")\n",
    "print(f\"  False Negatives: {fn:,}\")\n",
    "print(f\"  True Positives: {tp:,}\")\n",
    "print(f\"\\n  Accuracy: {(tp+tn)/(tp+tn+fp+fn):.4f}\")\n",
    "print(f\"  Precision (Fraud): {tp/(tp+fp):.4f}\")\n",
    "print(f\"  Recall (Fraud): {tp/(tp+fn):.4f}\")\n",
    "print(f\"  F1-Score (Fraud): {2*tp/(2*tp+fp+fn):.4f}\")\n",
    "print(f\"  ROC-AUC: {final_auc:.4f}\")\n",
    "print(f\"  PR-AUC: {final_ap:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccc31595",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====================================================\n",
    "# STEP 12: Visualization - Confusion Matrix & ROC Curves\n",
    "# ====================================================\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "\n",
    "# 1. Confusion Matrix Heatmap\n",
    "sns.heatmap(cm, annot=True, fmt=',d', cmap='Blues', ax=axes[0],\n",
    "            xticklabels=['Pred: Non-Fraud', 'Pred: Fraud'],\n",
    "            yticklabels=['Actual: Non-Fraud', 'Actual: Fraud'])\n",
    "axes[0].set_title('Confusion Matrix', fontsize=14)\n",
    "axes[0].set_ylabel('Actual')\n",
    "axes[0].set_xlabel('Predicted')\n",
    "\n",
    "# 2. ROC Curve\n",
    "fpr, tpr, thresholds = roc_curve(y_val, y_val_pred_proba_final)\n",
    "axes[1].plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (AUC = {final_auc:.4f})')\n",
    "axes[1].plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--', label='Random')\n",
    "axes[1].fill_between(fpr, tpr, alpha=0.3, color='darkorange')\n",
    "axes[1].set_xlim([0.0, 1.0])\n",
    "axes[1].set_ylim([0.0, 1.05])\n",
    "axes[1].set_xlabel('False Positive Rate', fontsize=12)\n",
    "axes[1].set_ylabel('True Positive Rate', fontsize=12)\n",
    "axes[1].set_title('ROC Curve', fontsize=14)\n",
    "axes[1].legend(loc='lower right')\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "# 3. Precision-Recall Curve\n",
    "precision, recall, _ = precision_recall_curve(y_val, y_val_pred_proba_final)\n",
    "axes[2].plot(recall, precision, color='green', lw=2, label=f'PR curve (AP = {final_ap:.4f})')\n",
    "axes[2].fill_between(recall, precision, alpha=0.3, color='green')\n",
    "axes[2].set_xlim([0.0, 1.0])\n",
    "axes[2].set_ylim([0.0, 1.05])\n",
    "axes[2].set_xlabel('Recall', fontsize=12)\n",
    "axes[2].set_ylabel('Precision', fontsize=12)\n",
    "axes[2].set_title('Precision-Recall Curve', fontsize=14)\n",
    "axes[2].legend(loc='lower left')\n",
    "axes[2].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5257cbdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====================================================\n",
    "# STEP 13: Feature Importance\n",
    "# ====================================================\n",
    "\n",
    "# Get feature importance\n",
    "feature_importance = pd.DataFrame({\n",
    "    'feature': X.columns,\n",
    "    'importance': final_lgb.feature_importances_\n",
    "}).sort_values('importance', ascending=False)\n",
    "\n",
    "# Plot top 20 features\n",
    "plt.figure(figsize=(12, 8))\n",
    "top_n = 20\n",
    "sns.barplot(\n",
    "    x='importance',\n",
    "    y='feature',\n",
    "    data=feature_importance.head(top_n),\n",
    "    palette='viridis'\n",
    ")\n",
    "plt.title(f'Top {top_n} Most Important Features (LightGBM)', fontsize=14)\n",
    "plt.xlabel('Importance Score')\n",
    "plt.ylabel('Feature')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nðŸ“‹ Top 20 Most Important Features:\")\n",
    "print(feature_importance.head(20).to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "096ab61a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====================================================\n",
    "# STEP 14: Predict on Test Data\n",
    "# ====================================================\n",
    "\n",
    "print(\"=\"*50)\n",
    "print(\"PREDICTING ON TEST DATA\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Predict probabilities on test data\n",
    "test_predictions = final_lgb.predict_proba(X_test_final)[:, 1]\n",
    "\n",
    "# Create submission DataFrame\n",
    "submission = pd.DataFrame({\n",
    "    'TransactionID': test_ids,\n",
    "    'isFraud': test_predictions\n",
    "})\n",
    "\n",
    "print(f\"\\nSubmission shape: {submission.shape}\")\n",
    "print(f\"\\nSubmission preview:\")\n",
    "print(submission.head(10))\n",
    "print(f\"\\nPrediction statistics:\")\n",
    "print(submission['isFraud'].describe())\n",
    "\n",
    "# Save submission\n",
    "submission.to_csv('./submission_lightgbm.csv', index=False)\n",
    "print(\"\\nâœ… Submission saved to 'submission_lightgbm.csv'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39aead32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====================================================\n",
    "# STEP 15: Model Summary\n",
    "# ====================================================\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"ðŸ“Š FINAL LightGBM MODEL SUMMARY\")\n",
    "print(\"=\"*60)\n",
    "print(f\"\"\"\n",
    "Dataset Information:\n",
    "--------------------\n",
    "â€¢ Training samples: {len(X_train):,}\n",
    "â€¢ Validation samples: {len(X_val):,}\n",
    "â€¢ Test samples: {len(X_test_final):,}\n",
    "â€¢ Number of features: {X_train.shape[1]}\n",
    "\n",
    "Class Distribution (Training):\n",
    "------------------------------\n",
    "â€¢ Non-Fraud: {(y_train == 0).sum():,} ({(y_train == 0).mean()*100:.2f}%)\n",
    "â€¢ Fraud: {(y_train == 1).sum():,} ({(y_train == 1).mean()*100:.2f}%)\n",
    "\n",
    "Model Configuration:\n",
    "-------------------\n",
    "â€¢ Model Type: LightGBM (Light Gradient Boosting Machine)\n",
    "â€¢ Number of Trees: {final_lgb.n_estimators}\n",
    "â€¢ Max Depth: {final_params.get('max_depth', 'N/A')}\n",
    "â€¢ Learning Rate: {final_params.get('learning_rate', 'N/A')}\n",
    "\n",
    "Performance Metrics:\n",
    "-------------------\n",
    "â€¢ ROC-AUC (Baseline): {baseline_auc:.4f}\n",
    "â€¢ ROC-AUC (Final): {final_auc:.4f}\n",
    "â€¢ PR-AUC: {final_ap:.4f}\n",
    "â€¢ Precision (Fraud): {tp/(tp+fp):.4f}\n",
    "â€¢ Recall (Fraud): {tp/(tp+fn):.4f}\n",
    "â€¢ F1-Score (Fraud): {2*tp/(2*tp+fp+fn):.4f}\n",
    "â€¢ Accuracy: {(tp+tn)/(tp+tn+fp+fn):.4f}\n",
    "\n",
    "Output Files:\n",
    "-------------\n",
    "â€¢ submission_lightgbm.csv - Test predictions\n",
    "\"\"\")\n",
    "print(\"=\"*60)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
