{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "809ffec6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LightGBM Version: 4.6.0\n",
      "âœ… Libraries imported successfully\n"
     ]
    }
   ],
   "source": [
    "# ====================================================\n",
    "# STEP 1: Import Libraries\n",
    "# ====================================================\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.metrics import (\n",
    "    roc_auc_score, classification_report, confusion_matrix, \n",
    "    roc_curve, precision_recall_curve, average_precision_score,\n",
    "    accuracy_score, precision_score, recall_score, f1_score\n",
    ")\n",
    "import lightgbm as lgb\n",
    "from lightgbm import LGBMClassifier\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"LightGBM Version:\", lgb.__version__)\n",
    "print(\"âœ… Libraries imported successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "026acce7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape: (590540, 394)\n",
      "Test shape: (506691, 393)\n",
      "\n",
      "Train dataset info:\n",
      "Columns: 394\n",
      "Rows: 590540\n"
     ]
    }
   ],
   "source": [
    "# ====================================================\n",
    "# STEP 2: Load Data\n",
    "# ====================================================\n",
    "\n",
    "train_transaction = pd.read_csv(f\"./train_transaction.csv\")\n",
    "test_transaction  = pd.read_csv(f\"./test_transaction.csv\")\n",
    "\n",
    "print(f\"Train shape: {train_transaction.shape}\")\n",
    "print(f\"Test shape: {test_transaction.shape}\")\n",
    "print(f\"\\nTrain dataset info:\")\n",
    "print(f\"Columns: {train_transaction.shape[1]}\")\n",
    "print(f\"Rows: {train_transaction.shape[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "35254344",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features shape: (590540, 392)\n",
      "Target shape: (590540,)\n",
      "Test features shape: (506691, 392)\n",
      "\n",
      "Numerical columns: 378\n",
      "Categorical columns: 14\n",
      "\n",
      "Numerical columns: 378\n",
      "Categorical columns: 14\n"
     ]
    }
   ],
   "source": [
    "# ====================================================\n",
    "# STEP 3: Data Preprocessing\n",
    "# ====================================================\n",
    "\n",
    "# Separate features and target\n",
    "X = train_transaction.drop(['isFraud', 'TransactionID'], axis=1)\n",
    "y = train_transaction['isFraud']\n",
    "X_test_final = test_transaction.drop(['TransactionID'], axis=1)\n",
    "test_ids = test_transaction['TransactionID']\n",
    "\n",
    "print(f\"Features shape: {X.shape}\")\n",
    "print(f\"Target shape: {y.shape}\")\n",
    "print(f\"Test features shape: {X_test_final.shape}\")\n",
    "\n",
    "# Identify column types\n",
    "numerical_cols = X.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
    "categorical_cols = X.select_dtypes(include=['object']).columns.tolist()\n",
    "\n",
    "print(f\"\\nNumerical columns: {len(numerical_cols)}\")\n",
    "print(f\"Categorical columns: {len(categorical_cols)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "52e6f719",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 20 columns with highest missing values (%)\n",
      "dist2    93.628374\n",
      "D7       93.409930\n",
      "D13      89.509263\n",
      "D14      89.469469\n",
      "D12      89.041047\n",
      "D6       87.606767\n",
      "D8       87.312290\n",
      "D9       87.312290\n",
      "V148     86.123717\n",
      "V147     86.123717\n",
      "V141     86.123717\n",
      "V140     86.123717\n",
      "V153     86.123717\n",
      "V158     86.123717\n",
      "V163     86.123717\n",
      "V155     86.123717\n",
      "V157     86.123717\n",
      "V161     86.123717\n",
      "V142     86.123717\n",
      "V138     86.123717\n",
      "dtype: float64\n",
      "\n",
      "Dropping 2 columns with >90% missing values\n",
      "New features shape: (590540, 390)\n",
      "New features shape: (590540, 390)\n"
     ]
    }
   ],
   "source": [
    "# ====================================================\n",
    "# STEP 4: Handle Missing Values\n",
    "# ====================================================\n",
    "\n",
    "# Check missing values percentage\n",
    "missing_pct = (X.isnull().sum() / len(X) * 100).sort_values(ascending=False)\n",
    "print(\"Top 20 columns with highest missing values (%)\")\n",
    "print(missing_pct.head(20))\n",
    "\n",
    "# Drop columns with >90% missing values\n",
    "high_missing_cols = missing_pct[missing_pct > 90].index.tolist()\n",
    "print(f\"\\nDropping {len(high_missing_cols)} columns with >90% missing values\")\n",
    "\n",
    "X = X.drop(columns=high_missing_cols)\n",
    "X_test_final = X_test_final.drop(columns=high_missing_cols)\n",
    "\n",
    "print(f\"New features shape: {X.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f4d1d00d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Categorical columns to encode: ['ProductCD', 'card4', 'card6', 'P_emaildomain', 'R_emaildomain', 'M1', 'M2', 'M3', 'M4', 'M5', 'M6', 'M7', 'M8', 'M9']\n",
      "\n",
      "âœ… Encoded 14 categorical columns\n",
      "Final X shape: (590540, 390)\n",
      "Final X_test shape: (506691, 390)\n",
      "\n",
      "âœ… Encoded 14 categorical columns\n",
      "Final X shape: (590540, 390)\n",
      "Final X_test shape: (506691, 390)\n"
     ]
    }
   ],
   "source": [
    "# ====================================================\n",
    "# STEP 5: Label Encoding for Categorical Columns\n",
    "# ====================================================\n",
    "\n",
    "# Update categorical columns list after dropping\n",
    "categorical_cols = X.select_dtypes(include=['object']).columns.tolist()\n",
    "print(f\"Categorical columns to encode: {categorical_cols}\")\n",
    "\n",
    "# Label Encoding\n",
    "label_encoders = {}\n",
    "for col in categorical_cols:\n",
    "    le = LabelEncoder()\n",
    "    # Combine train and test for consistent encoding\n",
    "    combined = pd.concat([X[col].astype(str), X_test_final[col].astype(str)])\n",
    "    le.fit(combined)\n",
    "    \n",
    "    X[col] = le.transform(X[col].astype(str))\n",
    "    X_test_final[col] = le.transform(X_test_final[col].astype(str))\n",
    "    label_encoders[col] = le\n",
    "\n",
    "print(f\"\\nâœ… Encoded {len(categorical_cols)} categorical columns\")\n",
    "print(f\"Final X shape: {X.shape}\")\n",
    "print(f\"Final X_test shape: {X_test_final.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3c16ee58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values in X after filling: 0\n",
      "Missing values in X_test after filling: 4787\n",
      "âœ… Data preprocessing completed\n",
      "Missing values in X_test after filling: 4787\n",
      "âœ… Data preprocessing completed\n"
     ]
    }
   ],
   "source": [
    "# ====================================================\n",
    "# STEP 6: Fill Remaining Missing Values\n",
    "# ====================================================\n",
    "\n",
    "# Fill numerical missing values with median\n",
    "numerical_cols = X.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
    "for col in numerical_cols:\n",
    "    if X[col].isnull().sum() > 0:\n",
    "        median_val = X[col].median()\n",
    "        X[col] = X[col].fillna(median_val)\n",
    "        X_test_final[col] = X_test_final[col].fillna(median_val)\n",
    "\n",
    "print(f\"Missing values in X after filling: {X.isnull().sum().sum()}\")\n",
    "print(f\"Missing values in X_test after filling: {X_test_final.isnull().sum().sum()}\")\n",
    "print(\"âœ… Data preprocessing completed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3b5ebf26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train-Validation Split:\n",
      "X_train: (472432, 390)\n",
      "X_val: (118108, 390)\n",
      "y_train distribution:\n",
      "isFraud\n",
      "0    0.965011\n",
      "1    0.034989\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "y_val distribution:\n",
      "isFraud\n",
      "0    0.965007\n",
      "1    0.034993\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "Class imbalance ratio: 1:27.58\n"
     ]
    }
   ],
   "source": [
    "# ====================================================\n",
    "# STEP 7: Train-Validation Split\n",
    "# ====================================================\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X, y,\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    "    stratify=y  # Stratified split to maintain class distribution\n",
    ")\n",
    "\n",
    "print(\"Train-Validation Split:\")\n",
    "print(f\"X_train: {X_train.shape}\")\n",
    "print(f\"X_val: {X_val.shape}\")\n",
    "print(f\"y_train distribution:\\n{y_train.value_counts(normalize=True)}\")\n",
    "print(f\"\\ny_val distribution:\\n{y_val.value_counts(normalize=True)}\")\n",
    "\n",
    "# Calculate class weights\n",
    "scale_pos_weight = (y_train == 0).sum() / (y_train == 1).sum()\n",
    "print(f\"\\nClass imbalance ratio: 1:{scale_pos_weight:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea8ccd10",
   "metadata": {},
   "source": [
    "## LightGBM Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ffb19a09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "TRAINING BASELINE LightGBM MODEL\n",
      "============================================================\n",
      "Baseline Parameters:\n",
      "  num_leaves: 31\n",
      "  max_depth: 8\n",
      "  learning_rate: 0.1\n",
      "  n_estimators: 100\n",
      "  subsample: 0.8\n",
      "  colsample_bytree: 0.8\n",
      "  scale_pos_weight: 27.580278281911674\n",
      "  objective: binary\n",
      "  metric: auc\n",
      "  random_state: 42\n",
      "  n_jobs: -1\n",
      "  verbose: -1\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[20]\ttraining's auc: 0.902463\tvalid_1's auc: 0.897106\n",
      "[20]\ttraining's auc: 0.902463\tvalid_1's auc: 0.897106\n",
      "[40]\ttraining's auc: 0.915337\tvalid_1's auc: 0.907956\n",
      "[40]\ttraining's auc: 0.915337\tvalid_1's auc: 0.907956\n",
      "[60]\ttraining's auc: 0.925599\tvalid_1's auc: 0.91602\n",
      "[60]\ttraining's auc: 0.925599\tvalid_1's auc: 0.91602\n",
      "[80]\ttraining's auc: 0.932949\tvalid_1's auc: 0.922002\n",
      "[80]\ttraining's auc: 0.932949\tvalid_1's auc: 0.922002\n",
      "[100]\ttraining's auc: 0.939601\tvalid_1's auc: 0.927111\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\ttraining's auc: 0.939601\tvalid_1's auc: 0.927111\n",
      "[100]\ttraining's auc: 0.939601\tvalid_1's auc: 0.927111\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\ttraining's auc: 0.939601\tvalid_1's auc: 0.927111\n",
      "\n",
      "ðŸŽ¯ Baseline Validation ROC-AUC: 0.9271\n",
      "ðŸŽ¯ Baseline Validation PR-AUC: 0.6115\n",
      "\n",
      "ðŸŽ¯ Baseline Validation ROC-AUC: 0.9271\n",
      "ðŸŽ¯ Baseline Validation PR-AUC: 0.6115\n"
     ]
    }
   ],
   "source": [
    "# ====================================================\n",
    "# STEP 8: Baseline LightGBM Model\n",
    "# ====================================================\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"TRAINING BASELINE LightGBM MODEL\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Baseline parameters\n",
    "# Note: LightGBM disallows setting both 'is_unbalance' and 'scale_pos_weight' at the same time.\n",
    "# We keep 'scale_pos_weight' (computed from data) and remove 'is_unbalance' to avoid LightGBMError.\n",
    "baseline_params = {\n",
    "    'num_leaves': 31,\n",
    "    'max_depth': 8,\n",
    "    'learning_rate': 0.1,\n",
    "    'n_estimators': 100,\n",
    "    'subsample': 0.8,\n",
    "    'colsample_bytree': 0.8,\n",
    "    'scale_pos_weight': scale_pos_weight,\n",
    "    'objective': 'binary',\n",
    "    'metric': 'auc',\n",
    "    'random_state': 42,\n",
    "    'n_jobs': -1,\n",
    "    'verbose': -1\n",
    "}\n",
    "\n",
    "print(\"Baseline Parameters:\")\n",
    "for key, value in baseline_params.items():\n",
    "    print(f\"  {key}: {value}\")\n",
    "\n",
    "# Train baseline model\n",
    "baseline_lgb = LGBMClassifier(**baseline_params)\n",
    "baseline_lgb.fit(\n",
    "    X_train, y_train,\n",
    "    eval_set=[(X_train, y_train), (X_val, y_val)],\n",
    "    callbacks=[\n",
    "        lgb.log_evaluation(period=20),\n",
    "        lgb.early_stopping(stopping_rounds=50)\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Baseline predictions\n",
    "y_val_pred_proba_baseline = baseline_lgb.predict_proba(X_val)[:, 1]\n",
    "baseline_auc = roc_auc_score(y_val, y_val_pred_proba_baseline)\n",
    "baseline_ap = average_precision_score(y_val, y_val_pred_proba_baseline)\n",
    "\n",
    "print(f\"\\nðŸŽ¯ Baseline Validation ROC-AUC: {baseline_auc:.4f}\")\n",
    "print(f\"ðŸŽ¯ Baseline Validation PR-AUC: {baseline_ap:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fe173bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-12-05 23:42:05,016] A new study created in memory with name: no-name-b716d015-7441-4a97-a76c-350182c22249\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optuna version: 4.6.0\n",
      "\n",
      "============================================================\n",
      "HYPERPARAMETER TUNING WITH OPTUNA\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/20 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[200]\tvalid_0's auc: 0.945249\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[200]\tvalid_0's auc: 0.945249\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[199]\tvalid_0's auc: 0.945244\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[199]\tvalid_0's auc: 0.945244\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[200]\tvalid_0's auc: 0.947651\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[200]\tvalid_0's auc: 0.947651\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 0. Best value: 0.946048:   5%|â–Œ         | 1/20 [01:12<22:50, 72.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-12-05 23:43:17,149] Trial 0 finished with value: 0.9460480394199354 and parameters: {'num_leaves': 50, 'max_depth': 15, 'learning_rate': 0.1205712628744377, 'subsample': 0.8795975452591109, 'colsample_bytree': 0.7468055921327309, 'min_child_samples': 9}. Best is trial 0 with value: 0.9460480394199354.\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[200]\tvalid_0's auc: 0.929151\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[200]\tvalid_0's auc: 0.929151\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[200]\tvalid_0's auc: 0.929102\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[200]\tvalid_0's auc: 0.929102\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[200]\tvalid_0's auc: 0.931153\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[200]\tvalid_0's auc: 0.931153\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 0. Best value: 0.946048:  10%|â–ˆ         | 2/20 [02:28<22:23, 74.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-12-05 23:44:33,579] Trial 1 finished with value: 0.9298019143920598 and parameters: {'num_leaves': 24, 'max_depth': 14, 'learning_rate': 0.07725378389307355, 'subsample': 0.9124217733388136, 'colsample_bytree': 0.7061753482887407, 'min_child_samples': 30}. Best is trial 0 with value: 0.9460480394199354.\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[200]\tvalid_0's auc: 0.912216\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[200]\tvalid_0's auc: 0.912216\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[200]\tvalid_0's auc: 0.914013\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[200]\tvalid_0's auc: 0.914013\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[200]\tvalid_0's auc: 0.914718\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[200]\tvalid_0's auc: 0.914718\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 0. Best value: 0.946048:  15%|â–ˆâ–Œ        | 3/20 [04:02<23:36, 83.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-12-05 23:46:07,265] Trial 2 finished with value: 0.9136490096107223 and parameters: {'num_leaves': 87, 'max_depth': 7, 'learning_rate': 0.01855998084649059, 'subsample': 0.7550213529560301, 'colsample_bytree': 0.7912726728878613, 'min_child_samples': 18}. Best is trial 0 with value: 0.9460480394199354.\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[199]\tvalid_0's auc: 0.939926\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[199]\tvalid_0's auc: 0.939926\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[199]\tvalid_0's auc: 0.938631\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[199]\tvalid_0's auc: 0.938631\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[200]\tvalid_0's auc: 0.940468\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[200]\tvalid_0's auc: 0.940468\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 0. Best value: 0.946048:  20%|â–ˆâ–ˆ        | 4/20 [05:07<20:20, 76.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-12-05 23:47:12,738] Trial 3 finished with value: 0.9396749018024101 and parameters: {'num_leaves': 54, 'max_depth': 8, 'learning_rate': 0.08012737503998542, 'subsample': 0.7418481581956126, 'colsample_bytree': 0.7876433945605654, 'min_child_samples': 14}. Best is trial 0 with value: 0.9460480394199354.\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[200]\tvalid_0's auc: 0.922421\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[200]\tvalid_0's auc: 0.922421\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[200]\tvalid_0's auc: 0.923456\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[200]\tvalid_0's auc: 0.923456\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[200]\tvalid_0's auc: 0.924409\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[200]\tvalid_0's auc: 0.924409\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 0. Best value: 0.946048:  25%|â–ˆâ–ˆâ–Œ       | 5/20 [06:55<21:57, 87.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-12-05 23:49:01,005] Trial 4 finished with value: 0.923428901276394 and parameters: {'num_leaves': 56, 'max_depth': 13, 'learning_rate': 0.019721610970574007, 'subsample': 0.8542703315240835, 'colsample_bytree': 0.8777243706586128, 'min_child_samples': 6}. Best is trial 0 with value: 0.9460480394199354.\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[200]\tvalid_0's auc: 0.898065\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[200]\tvalid_0's auc: 0.898065\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[199]\tvalid_0's auc: 0.900764\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[199]\tvalid_0's auc: 0.900764\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[200]\tvalid_0's auc: 0.900915\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[200]\tvalid_0's auc: 0.900915\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 0. Best value: 0.946048:  30%|â–ˆâ–ˆâ–ˆ       | 6/20 [07:50<17:50, 76.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-12-05 23:49:55,492] Trial 5 finished with value: 0.8999147350308184 and parameters: {'num_leaves': 69, 'max_depth': 6, 'learning_rate': 0.012476394272569451, 'subsample': 0.984665661176, 'colsample_bytree': 0.9896896099223678, 'min_child_samples': 26}. Best is trial 0 with value: 0.9460480394199354.\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[199]\tvalid_0's auc: 0.933508\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[199]\tvalid_0's auc: 0.933508\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[200]\tvalid_0's auc: 0.932296\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[200]\tvalid_0's auc: 0.932296\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[200]\tvalid_0's auc: 0.936972\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[200]\tvalid_0's auc: 0.936972\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 0. Best value: 0.946048:  35%|â–ˆâ–ˆâ–ˆâ–Œ      | 7/20 [08:41<14:45, 68.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-12-05 23:50:46,348] Trial 6 finished with value: 0.9342588571959967 and parameters: {'num_leaves': 44, 'max_depth': 6, 'learning_rate': 0.1024932221692416, 'subsample': 0.8320457481218804, 'colsample_bytree': 0.7366114704534336, 'min_child_samples': 17}. Best is trial 0 with value: 0.9460480394199354.\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[200]\tvalid_0's auc: 0.907179\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[200]\tvalid_0's auc: 0.907179\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[200]\tvalid_0's auc: 0.908196\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[200]\tvalid_0's auc: 0.908196\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[200]\tvalid_0's auc: 0.908963\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[200]\tvalid_0's auc: 0.908963\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 0. Best value: 0.946048:  40%|â–ˆâ–ˆâ–ˆâ–ˆ      | 8/20 [09:40<13:04, 65.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-12-05 23:51:45,883] Trial 7 finished with value: 0.9081127695958203 and parameters: {'num_leaves': 22, 'max_depth': 15, 'learning_rate': 0.024112898115291985, 'subsample': 0.8987566853061946, 'colsample_bytree': 0.7935133228268233, 'min_child_samples': 18}. Best is trial 0 with value: 0.9460480394199354.\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[200]\tvalid_0's auc: 0.94272\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[200]\tvalid_0's auc: 0.94272\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[200]\tvalid_0's auc: 0.938531\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[200]\tvalid_0's auc: 0.938531\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[187]\tvalid_0's auc: 0.943131\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[187]\tvalid_0's auc: 0.943131\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Best trial: 0. Best value: 0.946048:  45%|â–ˆâ–ˆâ–ˆâ–ˆâ–Œ     | 9/20 [10:31<11:09, 60.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[I 2025-12-05 23:52:36,831] Trial 8 finished with value: 0.9414605650959227 and parameters: {'num_leaves': 64, 'max_depth': 7, 'learning_rate': 0.27051668818999286, 'subsample': 0.9325398470083344, 'colsample_bytree': 0.9818496824692567, 'min_child_samples': 28}. Best is trial 0 with value: 0.9460480394199354.\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    }
   ],
   "source": [
    "# ====================================================\n",
    "# STEP 9: Hyperparameter Tuning with Optuna\n",
    "# ====================================================\n",
    "\n",
    "try:\n",
    "    import optuna\n",
    "    print(\"Optuna version:\", optuna.__version__)\n",
    "    \n",
    "    def objective(trial):\n",
    "        params = {\n",
    "            'num_leaves': trial.suggest_int('num_leaves', 20, 100),\n",
    "            'max_depth': trial.suggest_int('max_depth', 5, 15),\n",
    "            'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.3, log=True),\n",
    "            'subsample': trial.suggest_float('subsample', 0.7, 1.0),\n",
    "            'colsample_bytree': trial.suggest_float('colsample_bytree', 0.7, 1.0),\n",
    "            'min_child_samples': trial.suggest_int('min_child_samples', 5, 30),\n",
    "            'scale_pos_weight': scale_pos_weight,\n",
    "            # 'is_unbalance': True,  # Removed to avoid LightGBMError\n",
    "            'objective': 'binary',\n",
    "            'metric': 'auc',\n",
    "            'random_state': 42,\n",
    "            'n_jobs': -1,\n",
    "            'verbose': -1\n",
    "        }\n",
    "        \n",
    "        lgb_model = LGBMClassifier(n_estimators=200, **params)\n",
    "        \n",
    "        # Use stratified K-fold cross-validation\n",
    "        skf = StratifiedKFold(n_splits=3, shuffle=True, random_state=42)\n",
    "        scores = []\n",
    "        \n",
    "        for train_idx, val_idx in skf.split(X_train, y_train):\n",
    "            X_tr, X_v = X_train.iloc[train_idx], X_train.iloc[val_idx]\n",
    "            y_tr, y_v = y_train.iloc[train_idx], y_train.iloc[val_idx]\n",
    "            \n",
    "            lgb_model.fit(X_tr, y_tr, eval_set=[(X_v, y_v)], callbacks=[lgb.early_stopping(50), lgb.log_evaluation(0)])\n",
    "            y_pred = lgb_model.predict_proba(X_v)[:, 1]\n",
    "            auc = roc_auc_score(y_v, y_pred)\n",
    "            scores.append(auc)\n",
    "        \n",
    "        return np.mean(scores)\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"HYPERPARAMETER TUNING WITH OPTUNA\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    # Create study\n",
    "    sampler = optuna.samplers.TPESampler(seed=42)\n",
    "    study = optuna.create_study(direction='maximize', sampler=sampler)\n",
    "    \n",
    "    # Optimize (limited trials for faster execution)\n",
    "    study.optimize(objective, n_trials=20, show_progress_bar=True)\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"BEST PARAMETERS FOUND:\")\n",
    "    print(\"=\"*60)\n",
    "    best_params = study.best_params.copy()\n",
    "    for param, value in best_params.items():\n",
    "        print(f\"  {param}: {value}\")\n",
    "    print(f\"\\nBest CV AUC: {study.best_value:.4f}\")\n",
    "\n",
    "except ImportError:\n",
    "    print(\"âš ï¸ Optuna not installed. Skipping hyperparameter tuning.\")\n",
    "    print(\"Install with: pip install optuna\")\n",
    "    best_params = baseline_params.copy()\n",
    "    best_params.pop('n_estimators')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e7190e03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "TRAINING FINAL LightGBM MODEL\n",
      "============================================================\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[15], line 22\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;66;03m# Train final model\u001b[39;00m\n\u001b[0;32m     21\u001b[0m final_lgb \u001b[38;5;241m=\u001b[39m LGBMClassifier(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfinal_params)\n\u001b[1;32m---> 22\u001b[0m \u001b[43mfinal_lgb\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     23\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     24\u001b[0m \u001b[43m    \u001b[49m\u001b[43meval_set\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_val\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_val\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     25\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\n\u001b[0;32m     26\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlgb\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlog_evaluation\u001b[49m\u001b[43m(\u001b[49m\u001b[43mperiod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m50\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     27\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlgb\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mearly_stopping\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstopping_rounds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m50\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     28\u001b[0m \u001b[43m    \u001b[49m\u001b[43m]\u001b[49m\n\u001b[0;32m     29\u001b[0m \u001b[43m)\u001b[49m\n\u001b[0;32m     31\u001b[0m \u001b[38;5;66;03m# Final predictions\u001b[39;00m\n\u001b[0;32m     32\u001b[0m y_val_pred_proba_final \u001b[38;5;241m=\u001b[39m final_lgb\u001b[38;5;241m.\u001b[39mpredict_proba(X_val)[:, \u001b[38;5;241m1\u001b[39m]\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\lightgbm\\sklearn.py:1560\u001b[0m, in \u001b[0;36mLGBMClassifier.fit\u001b[1;34m(self, X, y, sample_weight, init_score, eval_set, eval_names, eval_sample_weight, eval_class_weight, eval_init_score, eval_metric, feature_name, categorical_feature, callbacks, init_model)\u001b[0m\n\u001b[0;32m   1557\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1558\u001b[0m             valid_sets\u001b[38;5;241m.\u001b[39mappend((valid_x, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_le\u001b[38;5;241m.\u001b[39mtransform(valid_y)))\n\u001b[1;32m-> 1560\u001b[0m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1561\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1562\u001b[0m \u001b[43m    \u001b[49m\u001b[43m_y\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1563\u001b[0m \u001b[43m    \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1564\u001b[0m \u001b[43m    \u001b[49m\u001b[43minit_score\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minit_score\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1565\u001b[0m \u001b[43m    \u001b[49m\u001b[43meval_set\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalid_sets\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1566\u001b[0m \u001b[43m    \u001b[49m\u001b[43meval_names\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meval_names\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1567\u001b[0m \u001b[43m    \u001b[49m\u001b[43meval_sample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meval_sample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1568\u001b[0m \u001b[43m    \u001b[49m\u001b[43meval_class_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meval_class_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1569\u001b[0m \u001b[43m    \u001b[49m\u001b[43meval_init_score\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meval_init_score\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1570\u001b[0m \u001b[43m    \u001b[49m\u001b[43meval_metric\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meval_metric\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1571\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfeature_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfeature_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1572\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcategorical_feature\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcategorical_feature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1573\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1574\u001b[0m \u001b[43m    \u001b[49m\u001b[43minit_model\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minit_model\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1575\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1576\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\lightgbm\\sklearn.py:1049\u001b[0m, in \u001b[0;36mLGBMModel.fit\u001b[1;34m(self, X, y, sample_weight, init_score, group, eval_set, eval_names, eval_sample_weight, eval_class_weight, eval_init_score, eval_group, eval_metric, feature_name, categorical_feature, callbacks, init_model)\u001b[0m\n\u001b[0;32m   1046\u001b[0m evals_result: _EvalResultDict \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m   1047\u001b[0m callbacks\u001b[38;5;241m.\u001b[39mappend(record_evaluation(evals_result))\n\u001b[1;32m-> 1049\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_Booster \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1050\u001b[0m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1051\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_set\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_set\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1052\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_boost_round\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_estimators\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1053\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalid_sets\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalid_sets\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1054\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalid_names\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meval_names\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1055\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfeval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meval_metrics_callable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[arg-type]\u001b[39;49;00m\n\u001b[0;32m   1056\u001b[0m \u001b[43m    \u001b[49m\u001b[43minit_model\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minit_model\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1057\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1058\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1060\u001b[0m \u001b[38;5;66;03m# This populates the property self.n_features_, the number of features in the fitted model,\u001b[39;00m\n\u001b[0;32m   1061\u001b[0m \u001b[38;5;66;03m# and so should only be set after fitting.\u001b[39;00m\n\u001b[0;32m   1062\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[0;32m   1063\u001b[0m \u001b[38;5;66;03m# The related property self._n_features_in, which populates self.n_features_in_,\u001b[39;00m\n\u001b[0;32m   1064\u001b[0m \u001b[38;5;66;03m# is set BEFORE fitting.\u001b[39;00m\n\u001b[0;32m   1065\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_n_features \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_Booster\u001b[38;5;241m.\u001b[39mnum_feature()\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\lightgbm\\engine.py:301\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(params, train_set, num_boost_round, valid_sets, valid_names, feval, init_model, keep_training_booster, callbacks)\u001b[0m\n\u001b[0;32m    299\u001b[0m         booster\u001b[38;5;241m.\u001b[39mset_train_data_name(train_data_name)\n\u001b[0;32m    300\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m valid_set, name_valid_set \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(reduced_valid_sets, name_valid_sets):\n\u001b[1;32m--> 301\u001b[0m         \u001b[43mbooster\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd_valid\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalid_set\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname_valid_set\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    302\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    303\u001b[0m     train_set\u001b[38;5;241m.\u001b[39m_reverse_update_params()\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\lightgbm\\basic.py:4058\u001b[0m, in \u001b[0;36mBooster.add_valid\u001b[1;34m(self, data, name)\u001b[0m\n\u001b[0;32m   4053\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m data\u001b[38;5;241m.\u001b[39m_predictor \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__init_predictor:\n\u001b[0;32m   4054\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m LightGBMError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAdd validation data failed, you should use same predictor for these data\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   4055\u001b[0m _safe_call(\n\u001b[0;32m   4056\u001b[0m     _LIB\u001b[38;5;241m.\u001b[39mLGBM_BoosterAddValidData(\n\u001b[0;32m   4057\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_handle,\n\u001b[1;32m-> 4058\u001b[0m         \u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconstruct\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39m_handle,\n\u001b[0;32m   4059\u001b[0m     )\n\u001b[0;32m   4060\u001b[0m )\n\u001b[0;32m   4061\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvalid_sets\u001b[38;5;241m.\u001b[39mappend(data)\n\u001b[0;32m   4062\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname_valid_sets\u001b[38;5;241m.\u001b[39mappend(name)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\lightgbm\\basic.py:2539\u001b[0m, in \u001b[0;36mDataset.construct\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   2536\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_params(reference_params)\n\u001b[0;32m   2537\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mused_indices \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   2538\u001b[0m     \u001b[38;5;66;03m# create valid\u001b[39;00m\n\u001b[1;32m-> 2539\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_lazy_init\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2540\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2541\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlabel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlabel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2542\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreference\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreference\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2543\u001b[0m \u001b[43m        \u001b[49m\u001b[43mweight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2544\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgroup\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2545\u001b[0m \u001b[43m        \u001b[49m\u001b[43mposition\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mposition\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2546\u001b[0m \u001b[43m        \u001b[49m\u001b[43minit_score\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minit_score\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2547\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpredictor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_predictor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2548\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfeature_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfeature_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2549\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcategorical_feature\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mauto\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2550\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2551\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   2553\u001b[0m     \u001b[38;5;66;03m# construct subset\u001b[39;00m\n\u001b[0;32m   2554\u001b[0m     used_indices \u001b[38;5;241m=\u001b[39m _list_to_1d_numpy(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mused_indices, dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mint32, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mused_indices\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\lightgbm\\basic.py:2187\u001b[0m, in \u001b[0;36mDataset._lazy_init\u001b[1;34m(self, data, label, reference, weight, group, init_score, predictor, feature_name, categorical_feature, params, position)\u001b[0m\n\u001b[0;32m   2185\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__init_from_csc(data, params_str, ref_dataset)\n\u001b[0;32m   2186\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, np\u001b[38;5;241m.\u001b[39mndarray):\n\u001b[1;32m-> 2187\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__init_from_np2d\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams_str\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mref_dataset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2188\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m _is_pyarrow_table(data):\n\u001b[0;32m   2189\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__init_from_pyarrow_table(data, params_str, ref_dataset)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\lightgbm\\basic.py:2319\u001b[0m, in \u001b[0;36mDataset.__init_from_np2d\u001b[1;34m(self, mat, params_str, ref_dataset)\u001b[0m\n\u001b[0;32m   2316\u001b[0m data, layout \u001b[38;5;241m=\u001b[39m _np2d_to_np1d(mat)\n\u001b[0;32m   2317\u001b[0m ptr_data, type_ptr_data, _ \u001b[38;5;241m=\u001b[39m _c_float_array(data)\n\u001b[0;32m   2318\u001b[0m _safe_call(\n\u001b[1;32m-> 2319\u001b[0m     \u001b[43m_LIB\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mLGBM_DatasetCreateFromMat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2320\u001b[0m \u001b[43m        \u001b[49m\u001b[43mptr_data\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2321\u001b[0m \u001b[43m        \u001b[49m\u001b[43mctypes\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mc_int\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtype_ptr_data\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2322\u001b[0m \u001b[43m        \u001b[49m\u001b[43mctypes\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mc_int32\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmat\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2323\u001b[0m \u001b[43m        \u001b[49m\u001b[43mctypes\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mc_int32\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmat\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2324\u001b[0m \u001b[43m        \u001b[49m\u001b[43mctypes\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mc_int\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlayout\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2325\u001b[0m \u001b[43m        \u001b[49m\u001b[43m_c_str\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams_str\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2326\u001b[0m \u001b[43m        \u001b[49m\u001b[43mref_dataset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2327\u001b[0m \u001b[43m        \u001b[49m\u001b[43mctypes\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbyref\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2328\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2329\u001b[0m )\n\u001b[0;32m   2330\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# ====================================================\n",
    "# STEP 10: Train Final LightGBM Model\n",
    "# ====================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"TRAINING FINAL LightGBM MODEL\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Final model parameters\n",
    "final_params = best_params.copy() if 'best_params' in locals() else baseline_params.copy()\n",
    "final_params.update({\n",
    "    'n_estimators': 500,\n",
    "    'objective': 'binary',\n",
    "    'metric': 'auc',\n",
    "    'random_state': 42,\n",
    "    'n_jobs': -1,\n",
    "    'verbose': -1\n",
    "})\n",
    "\n",
    "# Train final model\n",
    "final_lgb = LGBMClassifier(**final_params)\n",
    "final_lgb.fit(\n",
    "    X_train, y_train,\n",
    "    eval_set=[(X_train, y_train), (X_val, y_val)],\n",
    "    callbacks=[\n",
    "        lgb.log_evaluation(period=50),\n",
    "        lgb.early_stopping(stopping_rounds=50)\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Final predictions\n",
    "y_val_pred_proba_final = final_lgb.predict_proba(X_val)[:, 1]\n",
    "y_val_pred_final = (y_val_pred_proba_final > 0.5).astype(int)\n",
    "\n",
    "final_auc = roc_auc_score(y_val, y_val_pred_proba_final)\n",
    "final_ap = average_precision_score(y_val, y_val_pred_proba_final)\n",
    "\n",
    "print(f\"\\nðŸŽ¯ Final Model Validation ROC-AUC: {final_auc:.4f}\")\n",
    "print(f\"ðŸŽ¯ Final Model Validation PR-AUC: {final_ap:.4f}\")\n",
    "print(f\"ðŸ“ˆ Improvement over baseline: {(final_auc - baseline_auc) * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4039ab24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====================================================\n",
    "# STEP 11: Model Evaluation\n",
    "# ====================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"MODEL EVALUATION METRICS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Classification Report\n",
    "print(\"\\nðŸ“Š CLASSIFICATION REPORT:\")\n",
    "print(\"-\" * 40)\n",
    "print(classification_report(y_val, y_val_pred_final, target_names=['Non-Fraud', 'Fraud']))\n",
    "\n",
    "# Confusion Matrix\n",
    "cm = confusion_matrix(y_val, y_val_pred_final)\n",
    "print(\"\\nðŸ”¢ CONFUSION MATRIX:\")\n",
    "print(cm)\n",
    "\n",
    "# Additional Metrics\n",
    "tn, fp, fn, tp = cm.ravel()\n",
    "print(f\"\\nðŸ“ˆ ADDITIONAL METRICS:\")\n",
    "print(f\"  True Negatives: {tn:,}\")\n",
    "print(f\"  False Positives: {fp:,}\")\n",
    "print(f\"  False Negatives: {fn:,}\")\n",
    "print(f\"  True Positives: {tp:,}\")\n",
    "print(f\"\\n  Accuracy: {(tp+tn)/(tp+tn+fp+fn):.4f}\")\n",
    "print(f\"  Precision (Fraud): {tp/(tp+fp):.4f}\")\n",
    "print(f\"  Recall (Fraud): {tp/(tp+fn):.4f}\")\n",
    "print(f\"  F1-Score (Fraud): {2*tp/(2*tp+fp+fn):.4f}\")\n",
    "print(f\"  ROC-AUC: {final_auc:.4f}\")\n",
    "print(f\"  PR-AUC: {final_ap:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccc31595",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====================================================\n",
    "# STEP 12: Visualization - Confusion Matrix & ROC Curves\n",
    "# ====================================================\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "\n",
    "# 1. Confusion Matrix Heatmap\n",
    "sns.heatmap(cm, annot=True, fmt=',d', cmap='Blues', ax=axes[0],\n",
    "            xticklabels=['Pred: Non-Fraud', 'Pred: Fraud'],\n",
    "            yticklabels=['Actual: Non-Fraud', 'Actual: Fraud'])\n",
    "axes[0].set_title('Confusion Matrix', fontsize=14)\n",
    "axes[0].set_ylabel('Actual')\n",
    "axes[0].set_xlabel('Predicted')\n",
    "\n",
    "# 2. ROC Curve\n",
    "fpr, tpr, thresholds = roc_curve(y_val, y_val_pred_proba_final)\n",
    "axes[1].plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (AUC = {final_auc:.4f})')\n",
    "axes[1].plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--', label='Random')\n",
    "axes[1].fill_between(fpr, tpr, alpha=0.3, color='darkorange')\n",
    "axes[1].set_xlim([0.0, 1.0])\n",
    "axes[1].set_ylim([0.0, 1.05])\n",
    "axes[1].set_xlabel('False Positive Rate', fontsize=12)\n",
    "axes[1].set_ylabel('True Positive Rate', fontsize=12)\n",
    "axes[1].set_title('ROC Curve', fontsize=14)\n",
    "axes[1].legend(loc='lower right')\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "# 3. Precision-Recall Curve\n",
    "precision, recall, _ = precision_recall_curve(y_val, y_val_pred_proba_final)\n",
    "axes[2].plot(recall, precision, color='green', lw=2, label=f'PR curve (AP = {final_ap:.4f})')\n",
    "axes[2].fill_between(recall, precision, alpha=0.3, color='green')\n",
    "axes[2].set_xlim([0.0, 1.0])\n",
    "axes[2].set_ylim([0.0, 1.05])\n",
    "axes[2].set_xlabel('Recall', fontsize=12)\n",
    "axes[2].set_ylabel('Precision', fontsize=12)\n",
    "axes[2].set_title('Precision-Recall Curve', fontsize=14)\n",
    "axes[2].legend(loc='lower left')\n",
    "axes[2].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5257cbdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====================================================\n",
    "# STEP 13: Feature Importance\n",
    "# ====================================================\n",
    "\n",
    "# Get feature importance\n",
    "feature_importance = pd.DataFrame({\n",
    "    'feature': X.columns,\n",
    "    'importance': final_lgb.feature_importances_\n",
    "}).sort_values('importance', ascending=False)\n",
    "\n",
    "# Plot top 20 features\n",
    "plt.figure(figsize=(12, 8))\n",
    "top_n = 20\n",
    "sns.barplot(\n",
    "    x='importance',\n",
    "    y='feature',\n",
    "    data=feature_importance.head(top_n),\n",
    "    palette='viridis'\n",
    ")\n",
    "plt.title(f'Top {top_n} Most Important Features (LightGBM)', fontsize=14)\n",
    "plt.xlabel('Importance Score')\n",
    "plt.ylabel('Feature')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nðŸ“‹ Top 20 Most Important Features:\")\n",
    "print(feature_importance.head(20).to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "096ab61a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====================================================\n",
    "# STEP 14: Predict on Test Data\n",
    "# ====================================================\n",
    "\n",
    "print(\"=\"*50)\n",
    "print(\"PREDICTING ON TEST DATA\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Predict probabilities on test data\n",
    "test_predictions = final_lgb.predict_proba(X_test_final)[:, 1]\n",
    "\n",
    "# Create submission DataFrame\n",
    "submission = pd.DataFrame({\n",
    "    'TransactionID': test_ids,\n",
    "    'isFraud': test_predictions\n",
    "})\n",
    "\n",
    "print(f\"\\nSubmission shape: {submission.shape}\")\n",
    "print(f\"\\nSubmission preview:\")\n",
    "print(submission.head(10))\n",
    "print(f\"\\nPrediction statistics:\")\n",
    "print(submission['isFraud'].describe())\n",
    "\n",
    "# Save submission\n",
    "submission.to_csv('./submission_lightgbm.csv', index=False)\n",
    "print(\"\\nâœ… Submission saved to 'submission_lightgbm.csv'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39aead32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====================================================\n",
    "# STEP 15: Model Summary\n",
    "# ====================================================\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"ðŸ“Š FINAL LightGBM MODEL SUMMARY\")\n",
    "print(\"=\"*60)\n",
    "print(f\"\"\"\n",
    "Dataset Information:\n",
    "--------------------\n",
    "â€¢ Training samples: {len(X_train):,}\n",
    "â€¢ Validation samples: {len(X_val):,}\n",
    "â€¢ Test samples: {len(X_test_final):,}\n",
    "â€¢ Number of features: {X_train.shape[1]}\n",
    "\n",
    "Class Distribution (Training):\n",
    "------------------------------\n",
    "â€¢ Non-Fraud: {(y_train == 0).sum():,} ({(y_train == 0).mean()*100:.2f}%)\n",
    "â€¢ Fraud: {(y_train == 1).sum():,} ({(y_train == 1).mean()*100:.2f}%)\n",
    "\n",
    "Model Configuration:\n",
    "-------------------\n",
    "â€¢ Model Type: LightGBM (Light Gradient Boosting Machine)\n",
    "â€¢ Number of Trees: {final_lgb.n_estimators}\n",
    "â€¢ Max Depth: {final_params.get('max_depth', 'N/A')}\n",
    "â€¢ Learning Rate: {final_params.get('learning_rate', 'N/A')}\n",
    "\n",
    "Performance Metrics:\n",
    "-------------------\n",
    "â€¢ ROC-AUC (Baseline): {baseline_auc:.4f}\n",
    "â€¢ ROC-AUC (Final): {final_auc:.4f}\n",
    "â€¢ PR-AUC: {final_ap:.4f}\n",
    "â€¢ Precision (Fraud): {tp/(tp+fp):.4f}\n",
    "â€¢ Recall (Fraud): {tp/(tp+fn):.4f}\n",
    "â€¢ F1-Score (Fraud): {2*tp/(2*tp+fp+fn):.4f}\n",
    "â€¢ Accuracy: {(tp+tn)/(tp+tn+fp+fn):.4f}\n",
    "\n",
    "Output Files:\n",
    "-------------\n",
    "â€¢ submission_lightgbm.csv - Test predictions\n",
    "\"\"\")\n",
    "print(\"=\"*60)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
